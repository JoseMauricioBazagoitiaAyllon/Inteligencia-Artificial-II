{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "mount_file_id": "1kyJzmPXXelN3gPZfaKFOdvqWuywOsYyW",
      "authorship_tag": "ABX9TyPWQIpn9R1atlcYF/YVZg00",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoseMauricioBazagoitiaAyllon/Inteligencia-Artificial-II/blob/main/PrimerParcial2daP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMCdBKVkzN9R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(r'/content/drive/MyDrive/IA2/Temperaturas.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_time_series(batch_size, n_steps):\n",
        "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
        "    time = np.linspace(0, 1, n_steps)\n",
        "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   wave 1\n",
        "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
        "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + noise\n",
        "    return series[..., np.newaxis].astype(np.float32)\n",
        "\n",
        "n_steps = 50\n",
        "X_train = series[:7000, :n_steps]\n",
        "X_valid = series[7000:9000, :n_steps]\n",
        "X_test = series[9000:, :n_steps]\n",
        "Y = np.empty((10000, n_steps, 10), dtype=np.float32)\n",
        "for step_ahead in range(1, 10 + 1):\n",
        "    Y[..., step_ahead - 1] = series[..., step_ahead:step_ahead + n_steps, 0]\n",
        "Y_train = Y[:7000]\n",
        "Y_valid = Y[7000:9000]\n",
        "Y_test = Y[9000:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "fphDP3yMKJ2D",
        "outputId": "a2e3f87e-03a7-4f9a-f0d0-770fa020e978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-4a6feb98de77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'series' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train=data.values"
      ],
      "metadata": {
        "id": "YShFR4Hl6w47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6XbIS_bALHj",
        "outputId": "e4acd209-c2cd-4d79-99ce-b34a52a793c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1094, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = 50\n",
        "X_train, y_train = train[:800, :n_steps], train[:800, -1]\n",
        "X_valid, y_valid = train[800:900, :n_steps], train[800:900, -1]\n",
        "X_test, y_test = train[900:, :n_steps], train[900:, -1]"
      ],
      "metadata": {
        "id": "EvdEmuSPEiXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKdSVPsqFvue",
        "outputId": "eceeaf29-04e9-4c0f-d1bb-4560801538f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800, 1), (800,))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "def plot_series(series, y=None, y_pred=None, y_pred_std=None, x_label=\"$t$\", y_label=\"$x$\"):\n",
        "  r, c = 3, 5\n",
        "  fig, axes = plt.subplots(nrows=r, ncols=c, sharey=True, sharex=True, figsize=(20, 10))\n",
        "  for row in range(r):\n",
        "    for col in range(c):\n",
        "        plt.sca(axes[row][col])\n",
        "        ix = col + row*c\n",
        "        plt.plot(series[ix, :], \".-\")\n",
        "        if y is not None:\n",
        "            plt.plot(range(len(series[ix, :]), len(series[ix, :])+len(y[ix])), y[ix], \"bx\", markersize=10)\n",
        "        if y_pred is not None:\n",
        "            plt.plot(range(len(series[ix, :]), len(series[ix, :])+len(y_pred[ix])), y_pred[ix], \"ro\")\n",
        "        if y_pred_std is not None:\n",
        "            plt.plot(range(len(series[ix, :]), len(series[ix, :])+len(y_pred[ix])), y_pred[ix] + y_pred_std[ix])\n",
        "            plt.plot(range(len(series[ix, :]), len(series[ix, :])+len(y_pred[ix])), y_pred[ix] - y_pred_std[ix])\n",
        "        plt.grid(True)\n",
        "        plt.hlines(0, 0, 100, linewidth=1)\n",
        "        plt.axis([0, len(series[ix, :])+len(y[ix]), -1, 1])\n",
        "        if x_label and row == r - 1:\n",
        "          plt.xlabel(x_label, fontsize=16)\n",
        "        if y_label and col == 0:\n",
        "          plt.ylabel(y_label, fontsize=16, rotation=0)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "4vCfHmZLGbr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "  def __init__(self, X, y=None, train=True):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.train = train\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, ix):\n",
        "    if self.train:\n",
        "      return torch.from_numpy(self.X[ix]), torch.from_numpy(self.y[ix])\n",
        "    return torch.from_numpy(self.X[ix])\n",
        "\n",
        "dataset = {\n",
        "    'train': TimeSeriesDataset(X_train, y_train),\n",
        "    'eval': TimeSeriesDataset(X_valid, y_valid),\n",
        "    'test': TimeSeriesDataset(X_test, y_test, train=False)\n",
        "}\n",
        "\n",
        "dataloader = {\n",
        "    'train': DataLoader(dataset['train'], shuffle=True, batch_size=64),\n",
        "    'eval': DataLoader(dataset['eval'], shuffle=False, batch_size=64),\n",
        "    'test': DataLoader(dataset['test'], shuffle=False, batch_size=64)\n",
        "}"
      ],
      "metadata": {
        "id": "Tv8DyGRpF2nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def fit(model, dataloader, epochs=10):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    bar = tqdm(range(1, epochs+1))\n",
        "    for epoch in bar:\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        train_loss2 = []\n",
        "        for batch in dataloader['train']:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            train_loss2.append((y[:,-1] - y_hat[:,-1]).pow(2).mean().item())\n",
        "        model.eval()\n",
        "        eval_loss = []\n",
        "        eval_loss2 = []\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader['eval']:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                eval_loss.append(loss.item())\n",
        "                eval_loss2.append((y[:,-1] - y_hat[:,-1]).pow(2).mean().item())\n",
        "        bar.set_description(f\"loss {np.mean(train_loss):.5f} loss_last_step {np.mean(train_loss2):.5f} val_loss {np.mean(eval_loss):.5f} val_loss_last_step {np.mean(eval_loss2):.5f}\")\n",
        "\n",
        "def predict(model, dataloader):\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        preds = torch.tensor([]).to(device)\n",
        "        for batch in dataloader:\n",
        "            X = batch\n",
        "            X = X.to(device)\n",
        "            pred = model(X)\n",
        "            preds = torch.cat([preds, pred])\n",
        "        return preds"
      ],
      "metadata": {
        "id": "ZYGSpUkaDSS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepRNN(torch.nn.Module):\n",
        "  def __init__(self, n_in=50, n_out=1):\n",
        "    super().__init__()\n",
        "    self.rnn = torch.nn.RNN(input_size=1, hidden_size=20, num_layers=2, batch_first=True)\n",
        "    self.fc = torch.nn.Linear(20, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x, h = self.rnn(x) \n",
        "    x = self.fc(x[:,-1])\n",
        "    return x"
      ],
      "metadata": {
        "id": "Pn9TTvEBLHUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(DeepRNN):\n",
        "  def __init__(self, n_out=7, dropout=0):\n",
        "    super().__init__()\n",
        "    self.rnn = torch.nn.LSTM(input_size=1, hidden_size=20, num_layers=2, dropout=dropout, batch_first=True)\n",
        "    \n",
        "lstm = LSTM()"
      ],
      "metadata": {
        "id": "OE2CdCogJgcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def fit(model, dataloader, epochs=10):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    bar = tqdm(range(1, epochs+1))\n",
        "    for epoch in bar:\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        train_loss2 = []\n",
        "        for batch in dataloader['train']:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            train_loss2.append((y[:,-1] - y_hat[:,-1]).pow(2).mean().item())\n",
        "        model.eval()\n",
        "        eval_loss = []\n",
        "        eval_loss2 = []\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader['eval']:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                eval_loss.append(loss.item())\n",
        "                eval_loss2.append((y[:,-1] - y_hat[:,-1]).pow(2).mean().item())\n",
        "        bar.set_description(f\"loss {np.mean(train_loss):.5f} loss_last_step {np.mean(train_loss2):.5f} val_loss {np.mean(eval_loss):.5f} val_loss_last_step {np.mean(eval_loss2):.5f}\")\n",
        "\n",
        "def predict(model, dataloader):\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        preds = torch.tensor([]).to(device)\n",
        "        for batch in dataloader:\n",
        "            X = batch\n",
        "            X = X.to(device)\n",
        "            pred = model(X)\n",
        "            preds = torch.cat([preds, pred])\n",
        "        return preds"
      ],
      "metadata": {
        "id": "YnBIkQh8DSVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(DeepRNN):\n",
        "  def __init__(self, n_out=7, dropout=0):\n",
        "    super().__init__()\n",
        "    self.rnn = torch.nn.LSTM(input_size=1, hidden_size=20, num_layers=2, dropout=dropout, batch_first=True)\n",
        "    \n",
        "lstm = LSTM()"
      ],
      "metadata": {
        "id": "ZD47eet7DSaU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}